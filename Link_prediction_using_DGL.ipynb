{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gdu3AkUMeLsq",
        "outputId": "b3f97e93-a87d-46c4-f062-1beaaf8239de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl==0.6.1\n",
        "!pip install torch==1.9.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-lXOOe5f0ol",
        "outputId": "9e91ad3c-7eca-48f3-95bf-be12834b5c4a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dgl==0.6.1 in /usr/local/lib/python3.7/dist-packages (0.6.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl==0.6.1) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl==0.6.1) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl==0.6.1) (2.6.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl==0.6.1) (1.21.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl==0.6.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl==0.6.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl==0.6.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl==0.6.1) (2021.10.8)\n",
            "Collecting torch==1.9.1\n",
            "  Downloading torch-1.9.1-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 5.8 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.1) (4.2.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.9.1 which is incompatible.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.9.1 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.9.1 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import itertools\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import torch as th"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z5QxArjiJQs",
        "outputId": "8a8391af-8c27-404c-fc8a-44f16def8ba6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using backend: pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/PP-Pathways_ppi.csv', header = None)\n",
        "#ds = dgl.data.CSVDataset('/path/to/dataset')"
      ],
      "metadata": {
        "id": "kUE3cXKDfQKF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G=nx.from_pandas_edgelist(df,  0,  1,create_using=nx.Graph())\n",
        "g=dgl.from_networkx(G)\n",
        "g=dgl.to_bidirected(g)"
      ],
      "metadata": {
        "id": "hK7Oyy2Pipky"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"type: \",g.is_multigraph)\n",
        "print(\"No of nodes: \",g.number_of_nodes())\n",
        "print(\"No of edges: \",g.number_of_edges())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V8C4jpajbLW",
        "outputId": "f150a2a3-e8fc-4725-9593-156e0e5cde3d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type:  False\n",
            "No of nodes:  21557\n",
            "No of edges:  680989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating features for dataset i,e; `Degree`\n",
        "feature=g.in_degrees()\n",
        "feature=torch.reshape(feature, (21557,1))\n",
        "g.ndata['feat']=feature"
      ],
      "metadata": {
        "id": "MKQsPmGq2Qea"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### formulate the link prediction problem as a binary classification problem as follows:\n",
        "\n",
        "- Treat the edges in the graph as positive examples.\n",
        "- Sample a number of non-existent edges (i.e. node pairs with no edges between them) as negative examples.\n",
        "- Divide the positive examples and negative examples into a training set and a test set.\n",
        "- Evaluate the model with any binary classification metric such as Area Under Curve (AUC).\n",
        "\n",
        "- randomly pick 10% of the edges for positive examples in the test set, and leave the rest for the training set. Then samples the same number of edges for negative examples in both sets."
      ],
      "metadata": {
        "id": "AItvlgL1KTdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u, v = g.edges()\n",
        "eids = np.arange(g.number_of_edges())\n",
        "eids = np.random.permutation(eids)  #  Disorder the order \n",
        "\n",
        "test_size = int(len(eids) * 0.1)\n",
        "train_size = g.number_of_edges() - test_size\n",
        "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
        "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
        "\n",
        "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))  #  Use a full 1 vector , And corresponding u and v To construct adjacency matrix \n",
        "adj_neg = 1 - adj.todense() - np.eye(g.number_of_nodes())  #  Obtain the negative sampling adjacency matrix  adj.todense() Indicates that the sparse matrix adj Become a dense matrix \n",
        "neg_u, neg_v = np.where(adj_neg != 0)  #  Negative sampling on adjacency matrix \n",
        "\n",
        "neg_eids = np.random.choice(len(neg_u), g.number_of_edges())\n",
        "test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]\n",
        "train_neg_u, train_neg_v = neg_u[neg_eids[test_size:]], neg_v[neg_eids[test_size:]]"
      ],
      "metadata": {
        "id": "3jEGY672hQCz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_g = dgl.remove_edges(g, eids[:test_size])"
      ],
      "metadata": {
        "id": "tAIm-EBmibgN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.nn import SAGEConv\n",
        "\n",
        "# ----------- 2. create model -------------- #\n",
        "# build a two-layer GraphSAGE model\n",
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
        "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h"
      ],
      "metadata": {
        "id": "4dj8DtWeibjF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl.function as fn\n",
        "\n",
        "class DotPredictor(nn.Module):\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata['h'] = h\n",
        "            # Compute a new edge feature named 'score' by a dot-product between the\n",
        "            # source node feature 'h' and destination node feature 'h'.\n",
        "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
        "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
        "            return g.edata['score'][:, 0]"
      ],
      "metadata": {
        "id": "BM8oujiQFIrD"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.number_of_nodes())\n",
        "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.number_of_nodes())\n",
        "\n",
        "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.number_of_nodes())\n",
        "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.number_of_nodes())"
      ],
      "metadata": {
        "id": "9c7Dh4E1ibpT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_loss(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
        "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
        "\n",
        "def compute_auc(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
        "    labels = torch.cat(\n",
        "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
        "    return roc_auc_score(labels, scores)\n",
        "\n"
      ],
      "metadata": {
        "id": "-axkt-v4ib6P"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GraphSAGE(train_g.ndata['feat'].shape[1], 24)\n",
        "pred = DotPredictor()"
      ],
      "metadata": {
        "id": "UFjkISsKGTR6"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------- 3. set up loss and optimizer -------------- #\n",
        "# in this case, loss will in training loop\n",
        "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.01)\n",
        "\n",
        "# ----------- 4. training -------------------------------- #\n",
        "all_logits = []\n",
        "for e in range(350):\n",
        "    # forward\n",
        "    h = model(train_g, train_g.ndata['feat'].float())\n",
        "    pos_score = pred(train_pos_g, h)\n",
        "    neg_score = pred(train_neg_g, h)\n",
        "    loss = compute_loss(pos_score, neg_score)\n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if e % 5 == 0:\n",
        "        print('In epoch {}, loss: {}'.format(e, loss))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGc5xn5oEcAL",
        "outputId": "84e9bfe7-f079-45eb-d957-ecce9b64ec5d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In epoch 0, loss: 442800.09375\n",
            "In epoch 5, loss: 122178.1171875\n",
            "In epoch 10, loss: 25685.23046875\n",
            "In epoch 15, loss: 19105.470703125\n",
            "In epoch 20, loss: 17417.9453125\n",
            "In epoch 25, loss: 8113.88134765625\n",
            "In epoch 30, loss: 3722.365966796875\n",
            "In epoch 35, loss: 3048.437255859375\n",
            "In epoch 40, loss: 2821.181884765625\n",
            "In epoch 45, loss: 1980.25732421875\n",
            "In epoch 50, loss: 1224.3150634765625\n",
            "In epoch 55, loss: 918.4205932617188\n",
            "In epoch 60, loss: 816.375244140625\n",
            "In epoch 65, loss: 754.0439453125\n",
            "In epoch 70, loss: 686.319091796875\n",
            "In epoch 75, loss: 620.6762084960938\n",
            "In epoch 80, loss: 569.4276733398438\n",
            "In epoch 85, loss: 533.9817504882812\n",
            "In epoch 90, loss: 506.2844543457031\n",
            "In epoch 95, loss: 482.24755859375\n",
            "In epoch 100, loss: 462.0334777832031\n",
            "In epoch 105, loss: 442.71514892578125\n",
            "In epoch 110, loss: 425.3411865234375\n",
            "In epoch 115, loss: 408.9414367675781\n",
            "In epoch 120, loss: 393.9778137207031\n",
            "In epoch 125, loss: 379.5087890625\n",
            "In epoch 130, loss: 365.3929443359375\n",
            "In epoch 135, loss: 352.22039794921875\n",
            "In epoch 140, loss: 339.7619934082031\n",
            "In epoch 145, loss: 328.33587646484375\n",
            "In epoch 150, loss: 316.99017333984375\n",
            "In epoch 155, loss: 306.0364685058594\n",
            "In epoch 160, loss: 295.7252197265625\n",
            "In epoch 165, loss: 285.8545227050781\n",
            "In epoch 170, loss: 276.2319641113281\n",
            "In epoch 175, loss: 267.1722717285156\n",
            "In epoch 180, loss: 258.3447570800781\n",
            "In epoch 185, loss: 250.135986328125\n",
            "In epoch 190, loss: 241.90875244140625\n",
            "In epoch 195, loss: 234.1035614013672\n",
            "In epoch 200, loss: 226.60621643066406\n",
            "In epoch 205, loss: 219.57493591308594\n",
            "In epoch 210, loss: 212.73934936523438\n",
            "In epoch 215, loss: 206.31312561035156\n",
            "In epoch 220, loss: 200.05711364746094\n",
            "In epoch 225, loss: 200.27517700195312\n",
            "In epoch 230, loss: 188.70889282226562\n",
            "In epoch 235, loss: 183.2677001953125\n",
            "In epoch 240, loss: 176.7386016845703\n",
            "In epoch 245, loss: 179.1931610107422\n",
            "In epoch 250, loss: 167.67135620117188\n",
            "In epoch 255, loss: 161.28123474121094\n",
            "In epoch 260, loss: 161.5330810546875\n",
            "In epoch 265, loss: 162.99729919433594\n",
            "In epoch 270, loss: 152.14344787597656\n",
            "In epoch 275, loss: 148.56944274902344\n",
            "In epoch 280, loss: 139.83612060546875\n",
            "In epoch 285, loss: 135.6920623779297\n",
            "In epoch 290, loss: 137.72540283203125\n",
            "In epoch 295, loss: 131.4680938720703\n",
            "In epoch 300, loss: 125.41543579101562\n",
            "In epoch 305, loss: 123.6626968383789\n",
            "In epoch 310, loss: 117.59319305419922\n",
            "In epoch 315, loss: 117.6830062866211\n",
            "In epoch 320, loss: 111.51168823242188\n",
            "In epoch 325, loss: 106.73617553710938\n",
            "In epoch 330, loss: 105.61932373046875\n",
            "In epoch 335, loss: 100.5878677368164\n",
            "In epoch 340, loss: 98.00690460205078\n",
            "In epoch 345, loss: 95.09164428710938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------- 5. check results ------------------------ #\n",
        "from sklearn.metrics import roc_auc_score\n",
        "with torch.no_grad():\n",
        "    pos_score = pred(test_pos_g, h)\n",
        "    neg_score = pred(test_neg_g, h)\n",
        "    print('AUC', compute_auc(pos_score, neg_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXDeop_3FYPr",
        "outputId": "1adfe521-6fab-4f4e-c2a1-0c173a2cecd4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC 0.8093542052583326\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "Link prediction using DGL",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}